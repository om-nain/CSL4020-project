{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /Users/amolgaur/.cache/kagglehub/datasets/mohamedlotfy50/wmt-2014-english-german/versions/1\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 1: Imports, Setup, and Download Dataset Using Kaggle API\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Set the dataset path (adjust this path if needed)\n",
    "dataset_path = \"/Users/amolgaur/.cache/kagglehub/datasets/mohamedlotfy50/wmt-2014-english-german/versions/1\"\n",
    "print(\"Dataset downloaded to:\", dataset_path)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Cell 2: Load spaCy Models and Define Tokenizers\n",
    "import spacy\n",
    "\n",
    "# Ensure you have installed spaCy and downloaded the German and English models:\n",
    "# pip install spacy\n",
    "# python3 -m spacy download de_core_news_sm\n",
    "# python3 -m spacy download en_core_web_sm\n",
    "\n",
    "spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_de(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []  # Return empty list for non-string inputs\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pairs: 4509785\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 3: Load the WMT-2014 CSV Files (Columns: de,en)\n",
    "import pandas as pd\n",
    "\n",
    "def load_translation_pairs(split=\"train\"):\n",
    "    # Files are named like: wmt14_translate_de-en_train.csv, etc.\n",
    "    filename = f\"wmt14_translate_de-en_{split}.csv\"\n",
    "    csv_file = os.path.join(dataset_path, filename)\n",
    "    # Use the python engine and skip bad lines\n",
    "    df = pd.read_csv(csv_file, engine=\"python\", on_bad_lines=\"skip\")\n",
    "    # Expect columns \"de\" and \"en\" (if your CSV header is exactly \"de,en\")\n",
    "    pairs = df.to_dict(orient=\"records\")\n",
    "    return pairs\n",
    "\n",
    "train_pairs = load_translation_pairs(\"train\")\n",
    "valid_pairs = load_translation_pairs(\"validation\")\n",
    "test_pairs  = load_translation_pairs(\"test\")\n",
    "print(\"Number of training pairs:\", len(train_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German vocab size (source): 10000\n",
      "English vocab size (target): 10000\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 4: Build Vocabularies from the Dataset (Updated)\n",
    "from collections import Counter\n",
    "\n",
    "SPECIALS = [\"<sos>\", \"<eos>\", \"<pad>\"]\n",
    "\n",
    "def build_vocab(tokenizer, pairs, key, specials=SPECIALS, max_size=10000):\n",
    "    counter = Counter()\n",
    "    for pair in pairs:\n",
    "        text = pair.get(key)\n",
    "        # Skip if text is not a string (or is NaN)\n",
    "        if not isinstance(text, str):\n",
    "            continue  \n",
    "        tokens = tokenizer(text)\n",
    "        counter.update(tokens)\n",
    "    # Select the most common tokens, leaving space for special tokens\n",
    "    common_tokens = [token for token, _ in counter.most_common(max_size - len(specials))]\n",
    "    # Initialize vocab with special tokens\n",
    "    vocab = {token: idx for idx, token in enumerate(specials)}\n",
    "    for token in common_tokens:\n",
    "        vocab[token] = len(vocab)\n",
    "    # Build inverse vocabulary mapping (index â†’ token)\n",
    "    inv_vocab = {idx: token for token, idx in vocab.items()}\n",
    "    return vocab, inv_vocab\n",
    "\n",
    "# For translation from German (source) to English (target)\n",
    "vocab_src, inv_vocab_src = build_vocab(tokenize_de, train_pairs, key=\"de\", specials=SPECIALS, max_size=10000)\n",
    "vocab_trg, inv_vocab_trg = build_vocab(tokenize_en, train_pairs, key=\"en\", specials=SPECIALS, max_size=10000)\n",
    "\n",
    "print(\"German vocab size (source):\", len(vocab_src))\n",
    "print(\"English vocab size (target):\", len(vocab_trg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled training pairs: 100000\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 5: Data Processing and Collate Function\n",
    "def process_example(example):\n",
    "    if example.get(\"de\") is None or example.get(\"en\") is None:\n",
    "        return None  # Skip this example\n",
    "    # For translation from German (source) to English (target)\n",
    "    src_tokens = [\"<sos>\"] + tokenize_de(example[\"de\"]) + [\"<eos>\"]\n",
    "    trg_tokens = [\"<sos>\"] + tokenize_en(example[\"en\"]) + [\"<eos>\"]\n",
    "    src_indices = [vocab_src.get(token, vocab_src[\"<pad>\"]) for token in src_tokens]\n",
    "    trg_indices = [vocab_trg.get(token, vocab_trg[\"<pad>\"]) for token in trg_tokens]\n",
    "    src_tensor = torch.tensor(src_indices, dtype=torch.long)\n",
    "    trg_tensor = torch.tensor(trg_indices, dtype=torch.long)\n",
    "    return src_tensor, trg_tensor\n",
    "\n",
    "def process_split(pairs):\n",
    "    processed = [process_example(item) for item in pairs]\n",
    "    return [item for item in processed if item is not None]\n",
    "\n",
    "\n",
    "train_data = process_split(train_pairs)\n",
    "valid_data = process_split(valid_pairs)\n",
    "test_data  = process_split(test_pairs)\n",
    "\n",
    "# %% [code] New Cell: Subsample the Dataset for Memory Efficiency\n",
    "# For early experimentation, only use a subset of the full dataset.\n",
    "subsample_size = 100000  # adjust as needed\n",
    "train_data = train_data[:subsample_size]\n",
    "valid_data = valid_data[:5000]  # or an appropriate size for validation\n",
    "test_data  = test_data[:5000]\n",
    "print(\"Subsampled training pairs:\", len(train_data))\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=vocab_src[\"<pad>\"], batch_first=True)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=vocab_trg[\"<pad>\"], batch_first=True)\n",
    "    return src_batch, trg_batch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_data,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Cell 6.1: Positional Encoding Module (Reused)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([128, 112, 256])\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 7: Define the Convolutional Encoder\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, kernel_size=3, dropout=0.1):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_embedding = PositionalEncoding(embed_size)\n",
    "        self.fc = nn.Linear(embed_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size * 2,\n",
    "                      kernel_size=kernel_size, padding=(kernel_size - 1))\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    def forward(self, src):\n",
    "        # src: (batch_size, src_seq_len)\n",
    "        emb = self.embedding(src)               # (batch_size, src_seq_len, embed_size)\n",
    "        emb = self.pos_embedding(emb)\n",
    "        emb = self.fc(emb)                      # (batch_size, src_seq_len, hidden_size)\n",
    "        emb = self.dropout(emb)\n",
    "        conv_input = emb.transpose(1, 2)        # (batch_size, hidden_size, src_seq_len)\n",
    "        for conv in self.conv_layers:\n",
    "            conv_out = conv(conv_input)\n",
    "            conv_out = conv_out[:, :, :conv_input.size(2)]\n",
    "            glu_out = F.glu(conv_out, dim=1)     # (batch_size, hidden_size, src_seq_len)\n",
    "            conv_input = (glu_out + conv_input) * math.sqrt(0.5)\n",
    "        encoder_outputs = conv_input.transpose(1, 2)  # (batch_size, src_seq_len, hidden_size)\n",
    "        return encoder_outputs\n",
    "\n",
    "# Quick test\n",
    "src_batch, _ = next(iter(train_loader))\n",
    "encoder = ConvEncoder(len(vocab_src), embed_size=256, hidden_size=256, num_layers=4, kernel_size=3, dropout=0.1).to(device)\n",
    "enc_out = encoder(src_batch.to(device))\n",
    "print(\"Encoder output shape:\", enc_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: torch.Size([128, 73, 10000])\n",
      "Attention weights shape: torch.Size([128, 73, 112])\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 8: Define the Convolutional Decoder with Attention\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, kernel_size=3, dropout=0.1):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_embedding = PositionalEncoding(embed_size)\n",
    "        self.fc = nn.Linear(embed_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size * 2,\n",
    "                      kernel_size=kernel_size, padding=(kernel_size - 1))\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.attn_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "    def forward(self, tgt, encoder_outputs):\n",
    "        # tgt: (batch_size, tgt_seq_len)\n",
    "        emb = self.embedding(tgt)               # (batch_size, tgt_seq_len, embed_size)\n",
    "        emb = self.pos_embedding(emb)\n",
    "        emb = self.fc(emb)                      # (batch_size, tgt_seq_len, hidden_size)\n",
    "        emb = self.dropout(emb)\n",
    "        conv_input = emb.transpose(1, 2)        # (batch_size, hidden_size, tgt_seq_len)\n",
    "        for conv in self.conv_layers:\n",
    "            conv_out = conv(conv_input)\n",
    "            conv_out = conv_out[:, :, :conv_input.size(2)]\n",
    "            glu_out = F.glu(conv_out, dim=1)\n",
    "            conv_input = (glu_out + conv_input) * math.sqrt(0.5)\n",
    "        conv_output = conv_input.transpose(1, 2) # (batch_size, tgt_seq_len, hidden_size)\n",
    "        queries = self.attn_linear(conv_output)   # (batch_size, tgt_seq_len, hidden_size)\n",
    "        attn_scores = torch.bmm(queries, encoder_outputs.transpose(1,2))  # (batch_size, tgt_seq_len, src_seq_len)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)  # (batch_size, tgt_seq_len, hidden_size)\n",
    "        combined = conv_output + context\n",
    "        output = self.out(combined)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return output, attn_weights\n",
    "\n",
    "# Quick test\n",
    "_, trg_batch = next(iter(train_loader))\n",
    "decoder = ConvDecoder(len(vocab_trg), embed_size=256, hidden_size=256, num_layers=4, kernel_size=3, dropout=0.1).to(device)\n",
    "dec_out, attn_w = decoder(trg_batch.to(device), enc_out)\n",
    "print(\"Decoder output shape:\", dec_out.shape)\n",
    "print(\"Attention weights shape:\", attn_w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvSeq2Seq(\n",
      "  (encoder): ConvEncoder(\n",
      "    (embedding): Embedding(10000, 256)\n",
      "    (pos_embedding): PositionalEncoding()\n",
      "    (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (conv_layers): ModuleList(\n",
      "      (0-3): 4 x Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvDecoder(\n",
      "    (embedding): Embedding(10000, 256)\n",
      "    (pos_embedding): PositionalEncoding()\n",
      "    (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (conv_layers): ModuleList(\n",
      "      (0-3): 4 x Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "    )\n",
      "    (attn_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (out): Linear(in_features=256, out_features=10000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 9: Define the Full ConvSeq2Seq Model\n",
    "class ConvSeq2Seq(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, embed_size, hidden_size, num_layers, kernel_size=3, dropout=0.1):\n",
    "        super(ConvSeq2Seq, self).__init__()\n",
    "        self.encoder = ConvEncoder(src_vocab_size, embed_size, hidden_size, num_layers, kernel_size, dropout)\n",
    "        self.decoder = ConvDecoder(tgt_vocab_size, embed_size, hidden_size, num_layers, kernel_size, dropout)\n",
    "    def forward(self, src, tgt):\n",
    "        encoder_outputs = self.encoder(src)\n",
    "        decoder_outputs, attn_weights = self.decoder(tgt, encoder_outputs)\n",
    "        return decoder_outputs, attn_weights\n",
    "\n",
    "INPUT_DIM = len(vocab_src)\n",
    "OUTPUT_DIM = len(vocab_trg)\n",
    "model = ConvSeq2Seq(INPUT_DIM, OUTPUT_DIM, embed_size=256, hidden_size=256, num_layers=4, kernel_size=3, dropout=0.1).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Cell 10: Define Optimizer and Loss Function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "PAD_IDX = vocab_trg[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code] Cell 11: Define Training and Evaluation Functions\n",
    "def train_epoch(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        # Teacher forcing: input to decoder is trg[:, :-1], target is trg[:, 1:]\n",
    "        output, _ = model(src, trg[:, :-1])\n",
    "        output = output.contiguous().view(-1, output.shape[-1])\n",
    "        trg_target = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = criterion(output, trg_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate_epoch(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in iterator:\n",
    "            output, _ = model(src, trg[:, :-1])\n",
    "            output = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg_target = trg[:, 1:].contiguous().view(-1)\n",
    "            loss = criterion(output, trg_target)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed = end_time - start_time\n",
    "    mins = int(elapsed / 60)\n",
    "    secs = int(elapsed - mins * 60)\n",
    "    return mins, secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 66m 22s\n",
      "\tTrain Loss: 4.595\n",
      "\t Val. Loss: 4.689\n",
      "Epoch: 02 | Time: 65m 36s\n",
      "\tTrain Loss: 4.303\n",
      "\t Val. Loss: 4.544\n",
      "Epoch: 03 | Time: 65m 15s\n",
      "\tTrain Loss: 4.108\n",
      "\t Val. Loss: 4.432\n",
      "Epoch: 04 | Time: 65m 10s\n",
      "\tTrain Loss: 3.973\n",
      "\t Val. Loss: 4.385\n",
      "Epoch: 05 | Time: 64m 55s\n",
      "\tTrain Loss: 3.875\n",
      "\t Val. Loss: 4.340\n",
      "Epoch: 06 | Time: 64m 50s\n",
      "\tTrain Loss: 3.797\n",
      "\t Val. Loss: 4.301\n",
      "Epoch: 07 | Time: 64m 45s\n",
      "\tTrain Loss: 3.733\n",
      "\t Val. Loss: 4.267\n",
      "Epoch: 08 | Time: 64m 40s\n",
      "\tTrain Loss: 3.681\n",
      "\t Val. Loss: 4.240\n",
      "Epoch: 09 | Time: 64m 35s\n",
      "\tTrain Loss: 3.642\n",
      "\t Val. Loss: 4.218\n",
      "Epoch: 10 | Time: 64m 30s\n",
      "\tTrain Loss: 3.613\n",
      "\t Val. Loss: 4.200\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 12: Full Training Loop\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    valid_loss = evaluate_epoch(model, valid_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'convseq2seq-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: A small house with a garden . <eos>\n"
     ]
    }
   ],
   "source": [
    "# %% [code] Cell 13: Greedy Decoding for Inference\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
    "    model.eval()\n",
    "    # Tokenize the input sentence using the German tokenizer\n",
    "    tokens = [token.lower() for token in tokenize_de(sentence)]\n",
    "    # Add start and end tokens\n",
    "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
    "    # Convert tokens to indices (fallback to <pad> if token not found)\n",
    "    src_indices = [src_vocab.get(token, src_vocab[\"<pad>\"]) for token in tokens]\n",
    "    # Create tensor and add batch dimension\n",
    "    src_tensor = torch.LongTensor(src_indices).unsqueeze(0).to(device)  # shape: (1, src_seq_len)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.encoder(src_tensor)\n",
    "    \n",
    "    # Initialize target sequence with <sos>\n",
    "    trg_indices = [trg_vocab[\"<sos>\"]]\n",
    "    for i in range(max_len - 1):\n",
    "        trg_tensor = torch.LongTensor(trg_indices).unsqueeze(0).to(device)  # shape: (1, current_len)\n",
    "        with torch.no_grad():\n",
    "            output, _ = model.decoder(trg_tensor, encoder_outputs)\n",
    "        # Get the token with the highest probability from the last time step\n",
    "        next_token = output[:, -1, :].argmax(dim=-1).item()\n",
    "        trg_indices.append(next_token)\n",
    "        if next_token == trg_vocab[\"<eos>\"]:\n",
    "            break\n",
    "    # Convert indices back to tokens using the inverse target vocabulary\n",
    "    trg_tokens = [inv_vocab_trg[i] for i in trg_indices]\n",
    "    # Return the decoded tokens, excluding the initial <sos>\n",
    "    return trg_tokens[1:]\n",
    "\n",
    "# Test translation on a sample German sentence\n",
    "example_sentence = \"Ein kleines Haus mit einem Garten .\"\n",
    "translation = translate_sentence(example_sentence, vocab_src, vocab_trg, model, device)\n",
    "print(\"Translated:\", \" \".join(translation))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
